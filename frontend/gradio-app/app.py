import gradio as gr
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json
import boto3
from typing import Dict, List, Tuple
import os
import requests
from transformers import pipeline
import asyncio
import concurrent.futures
from components.data_visualizer import DataVisualizer
from components.sentiment_analyzer import SentimentAnalyzer
from components.report_generator import ReportGenerator

class SocialListeningApp:
    def __init__(self):
        self.data_visualizer = DataVisualizer()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.report_generator = ReportGenerator()
        
        # AWSè¨­å®š
        self.dynamodb = boto3.resource('dynamodb', region_name=os.getenv('AWS_REGION', 'us-east-1'))
        self.bedrock = boto3.client('bedrock-runtime', region_name=os.getenv('AWS_REGION', 'us-east-1'))
        self.api_gateway_url = os.getenv('API_GATEWAY_URL')
        
        # Hugging Face ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.sentiment_pipeline = pipeline("sentiment-analysis", 
                                          model="cardiffnlp/twitter-roberta-base-sentiment-latest")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
        self.posts_table = self.dynamodb.Table(os.getenv('POSTS_TABLE', 'social-posts'))
        self.analytics_table = self.dynamodb.Table(os.getenv('ANALYTICS_TABLE', 'social-analytics'))

    def fetch_posts_data(self, keyword: str, date_range: int = 7) -> pd.DataFrame:
        """DynamoDBã‹ã‚‰æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=date_range)
            
            response = self.posts_table.scan(
                FilterExpression=boto3.dynamodb.conditions.Attr('keyword').contains(keyword) &
                               boto3.dynamodb.conditions.Attr('timestamp').between(
                                   start_date.isoformat(), end_date.isoformat()
                               )
            )
            
            items = response['Items']
            df = pd.DataFrame(items)
            
            if not df.empty:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df = df.sort_values('timestamp', ascending=False)
            
            return df
            
        except Exception as e:
            gr.Warning(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()

    def analyze_sentiment_with_bedrock(self, text: str) -> Dict:
        """Bedrock Novaã§æ„Ÿæƒ…åˆ†æ"""
        try:
            prompt = f"""
            ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
            
            ãƒ†ã‚­ã‚¹ãƒˆ: {text}
            
            ä»¥ä¸‹ã®å½¢å¼ã§JSONã§å›ç­”ã—ã¦ãã ã•ã„:
            {{
                "sentiment": "positive/negative/neutral",
                "confidence": 0.0-1.0,
                "emotions": ["joy", "anger", "sadness", "fear", "surprise"],
                "summary": "åˆ†æçµæœã®è¦ç´„"
            }}
            """
            
            response = self.bedrock.invoke_model(
                modelId="amazon.nova-micro-v1:0",
                body=json.dumps({
                    "inputText": prompt,
                    "textGenerationConfig": {
                        "maxTokenCount": 500,
                        "temperature": 0.1
                    }
                })
            )
            
            result = json.loads(response['body'].read())
            return json.loads(result['results'][0]['outputText'])
            
        except Exception as e:
            return {
                "sentiment": "neutral",
                "confidence": 0.5,
                "emotions": [],
                "summary": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
            }

    def analyze_sentiment_with_huggingface(self, texts: List[str]) -> List[Dict]:
        """Hugging Faceã§æ„Ÿæƒ…åˆ†æ"""
        try:
            results = self.sentiment_pipeline(texts)
            return [
                {
                    "sentiment": result['label'].lower(),
                    "confidence": result['score'],
                    "text": text
                }
                for result, text in zip(results, texts)
            ]
        except Exception as e:
            gr.Warning(f"æ„Ÿæƒ…åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []

    def extract_posts(self, keyword: str, platform: str, count: int = 100) -> str:
        """API GatewayçµŒç”±ã§æŠ•ç¨¿ã‚’æŠ½å‡º"""
        try:
            response = requests.post(
                f"{self.api_gateway_url}/extract-posts",
                json={
                    "keyword": keyword,
                    "platform": platform,
                    "count": count
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return f"âœ… {result.get('extracted_count', 0)}ä»¶ã®æŠ•ç¨¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸ"
            else:
                return f"âŒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {response.text}"
                
        except Exception as e:
            return f"âŒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"

    def create_sentiment_chart(self, df: pd.DataFrame) -> go.Figure:
        """æ„Ÿæƒ…åˆ†æãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
        if df.empty:
            return go.Figure().add_annotation(text="ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“", showarrow=False)
        
        sentiment_counts = df['sentiment'].value_counts()
        
        fig = px.pie(
            values=sentiment_counts.values,
            names=sentiment_counts.index,
            title="æ„Ÿæƒ…åˆ†æçµæœ",
            color_discrete_map={
                'positive': '#2E8B57',
                'negative': '#DC143C',
                'neutral': '#708090'
            }
        )
        
        return fig

    def create_timeline_chart(self, df: pd.DataFrame) -> go.Figure:
        """æ™‚ç³»åˆ—ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
        if df.empty:
            return go.Figure().add_annotation(text="ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“", showarrow=False)
        
        # æ—¥åˆ¥æŠ•ç¨¿æ•°
        daily_counts = df.groupby(df['timestamp'].dt.date).size().reset_index()
        daily_counts.columns = ['date', 'count']
        
        fig = px.line(
            daily_counts,
            x='date',
            y='count',
            title="æ—¥åˆ¥æŠ•ç¨¿æ•°æ¨ç§»",
            markers=True
        )
        
        fig.update_layout(
            xaxis_title="æ—¥ä»˜",
            yaxis_title="æŠ•ç¨¿æ•°"
        )
        
        return fig

    def create_word_frequency_chart(self, df: pd.DataFrame) -> go.Figure:
        """å˜èªé »åº¦ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
        if df.empty:
            return go.Figure().add_annotation(text="ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“", showarrow=False)
        
        # ç°¡å˜ãªå˜èªåˆ†æï¼ˆå®Ÿéš›ã«ã¯MeCabãªã©ã‚’ä½¿ç”¨ï¼‰
        all_text = ' '.join(df['content'].astype(str))
        words = all_text.split()
        word_freq = pd.Series(words).value_counts().head(20)
        
        fig = px.bar(
            x=word_freq.values,
            y=word_freq.index,
            orientation='h',
            title="é »å‡ºå˜èªTOP20"
        )
        
        fig.update_layout(
            xaxis_title="å‡ºç¾å›æ•°",
            yaxis_title="å˜èª"
        )
        
        return fig

    def generate_summary_report(self, df: pd.DataFrame, keyword: str) -> str:
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        if df.empty:
            return "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        
        total_posts = len(df)
        sentiment_dist = df['sentiment'].value_counts()
        
        # Bedrockã§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        prompt = f"""
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keyword}ã€ã«é–¢ã™ã‚‹ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:
        - ç·æŠ•ç¨¿æ•°: {total_posts}
        - æ„Ÿæƒ…åˆ†å¸ƒ: {sentiment_dist.to_dict()}
        - æœŸé–“: {df['timestamp'].min()} - {df['timestamp'].max()}
        
        ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚ã¦æ—¥æœ¬èªã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„:
        1. æ¦‚è¦
        2. æ„Ÿæƒ…åˆ†æçµæœ
        3. ä¸»è¦ãªãƒˆãƒ¬ãƒ³ãƒ‰
        4. æ³¨ç›®ã™ã¹ãæŠ•ç¨¿
        5. æ”¹å–„ææ¡ˆ
        """
        
        try:
            response = self.bedrock.invoke_model(
                modelId="amazon.nova-micro-v1:0",
                body=json.dumps({
                    "inputText": prompt,
                    "textGenerationConfig": {
                        "maxTokenCount": 1000,
                        "temperature": 0.3
                    }
                })
            )
            
            result = json.loads(response['body'].read())
            return result['results'][0]['outputText']
            
        except Exception as e:
            return f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"

    def build_interface(self):
        """Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ§‹ç¯‰"""
        
        with gr.Blocks(title="Social Listening Tool", theme=gr.themes.Soft()) as app:
            gr.Markdown("# ğŸ” ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒªã‚¹ãƒ‹ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«")
            gr.Markdown("SNSã®æŠ•ç¨¿ã‚’åˆ†æã—ã¦ã€ãƒ–ãƒ©ãƒ³ãƒ‰ã‚„å•†å“ã«é–¢ã™ã‚‹è©•åˆ¤ã‚’ç›£è¦–ã—ã¾ã™")
            
            with gr.Tabs() as tabs:
                # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¿ãƒ–
                with gr.TabItem("ğŸ“Š ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"):
                    with gr.Row():
                        with gr.Column():
                            keyword_input = gr.Textbox(
                                label="æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                                placeholder="ä¾‹: æ–°å•†å“, ãƒ–ãƒ©ãƒ³ãƒ‰å",
                                value=""
                            )
                            platform_select = gr.Dropdown(
                                choices=["twitter", "instagram", "facebook", "all"],
                                label="ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ",
                                value="twitter"
                            )
                            count_slider = gr.Slider(
                                minimum=10,
                                maximum=1000,
                                value=100,
                                step=10,
                                label="æŠ½å‡ºä»¶æ•°"
                            )
                            extract_btn = gr.Button("ğŸ” æŠ•ç¨¿ã‚’æŠ½å‡º", variant="primary")
                        
                        with gr.Column():
                            extract_status = gr.Textbox(
                                label="æŠ½å‡ºçŠ¶æ³",
                                interactive=False,
                                lines=3
                            )
                
                # åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¿ãƒ–
                with gr.TabItem("ğŸ“ˆ åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"):
                    with gr.Row():
                        with gr.Column(scale=1):
                            analysis_keyword = gr.Textbox(
                                label="åˆ†æã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                                placeholder="åˆ†æã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›"
                            )
                            date_range = gr.Slider(
                                minimum=1,
                                maximum=30,
                                value=7,
                                step=1,
                                label="åˆ†ææœŸé–“ï¼ˆæ—¥ï¼‰"
                            )
                            analyze_btn = gr.Button("ğŸ“Š åˆ†æå®Ÿè¡Œ", variant="primary")
                            refresh_btn = gr.Button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ›´æ–°")
                        
                        with gr.Column(scale=3):
                            with gr.Row():
                                sentiment_chart = gr.Plot(label="æ„Ÿæƒ…åˆ†æ")
                                timeline_chart = gr.Plot(label="æ™‚ç³»åˆ—æ¨ç§»")
                            
                            word_freq_chart = gr.Plot(label="é »å‡ºå˜èª")
                
                # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–
                with gr.TabItem("ğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ"):
                    with gr.Row():
                        with gr.Column():
                            report_keyword = gr.Textbox(
                                label="ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                                placeholder="ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"
                            )
                            report_btn = gr.Button("ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ", variant="primary")
                        
                        with gr.Column(scale=2):
                            report_output = gr.Textbox(
                                label="åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
                                lines=15,
                                interactive=False
                            )
                
                # æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚¿ãƒ–
                with gr.TabItem("ğŸ’¬ æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿"):
                    with gr.Row():
                        with gr.Column():
                            viewer_keyword = gr.Textbox(
                                label="è¡¨ç¤ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                                placeholder="è¡¨ç¤ºã™ã‚‹æŠ•ç¨¿ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"
                            )
                            load_posts_btn = gr.Button("ğŸ“„ æŠ•ç¨¿ã‚’èª­ã¿è¾¼ã¿")
                        
                        with gr.Column(scale=3):
                            posts_dataframe = gr.Dataframe(
                                headers=["æ—¥æ™‚", "ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ", "å†…å®¹", "æ„Ÿæƒ…", "ä¿¡é ¼åº¦"],
                                interactive=False
                            )
            
            # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            extract_btn.click(
                fn=self.extract_posts,
                inputs=[keyword_input, platform_select, count_slider],
                outputs=extract_status
            )
            
            def analyze_data(keyword, days):
                df = self.fetch_posts_data(keyword, days)
                
                sentiment_fig = self.create_sentiment_chart(df)
                timeline_fig = self.create_timeline_chart(df)
                word_freq_fig = self.create_word_frequency_chart(df)
                
                return sentiment_fig, timeline_fig, word_freq_fig
            
            analyze_btn.click(
                fn=analyze_data,
                inputs=[analysis_keyword, date_range],
                outputs=[sentiment_chart, timeline_chart, word_freq_chart]
            )
            
            refresh_btn.click(
                fn=analyze_data,
                inputs=[analysis_keyword, date_range],
                outputs=[sentiment_chart, timeline_chart, word_freq_chart]
            )
            
            report_btn.click(
                fn=lambda keyword: self.generate_summary_report(
                    self.fetch_posts_data(keyword), keyword
                ),
                inputs=report_keyword,
                outputs=report_output
            )
            
            def load_posts_table(keyword):
                df = self.fetch_posts_data(keyword)
                if df.empty:
                    return []
                
                # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                display_data = []
                for _, row in df.head(100).iterrows():
                    display_data.append([
                        row['timestamp'].strftime('%Y-%m-%d %H:%M'),
                        row.get('platform', 'unknown'),
                        row['content'][:100] + "..." if len(row['content']) > 100 else row['content'],
                        row.get('sentiment', 'unknown'),
                        f"{row.get('confidence', 0):.2f}"
                    ])
                
                return display_data
            
            load_posts_btn.click(
                fn=load_posts_table,
                inputs=viewer_keyword,
                outputs=posts_dataframe
            )
        
        return app

def main():
    app = SocialListeningApp()
    interface = app.build_interface()
    
    # Lambdaç’°å¢ƒã®å ´åˆã¯interfaceã‚’è¿”ã™ã ã‘
    if os.getenv('AWS_LAMBDA_FUNCTION_NAME'):
        return interface
    
    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆã¯èµ·å‹•
    port = int(os.getenv('PORT', 7860))
    host = os.getenv('HOST', '0.0.0.0')
    
    interface.launch(
        server_name=host,
        server_port=port,
        share=False,
        debug=os.getenv('DEBUG', 'False').lower() == 'true'
    )
    
    return interface
if __name__ == "__main__":
    main()
